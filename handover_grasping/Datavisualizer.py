# AUTOGENERATED! DO NOT EDIT! File to edit: 00_Datavisualizer.ipynb (unless otherwise specified).

__all__ = ['handover_grasping_dataset', 'rosenberger_dataloader']

# Cell
import torchvision.transforms as transforms
import cv2
from torch.utils.data import Dataset
import numpy as np


class handover_grasping_dataset(Dataset):
    """Dataloader of handover datasets.
    """
    name = []
    def __init__(self, data_dir, mode='train', color_type='jpg', depth_type='npy'):
        self.image_net_mean = np.array([0.485, 0.456, 0.406])
        self.image_net_std  = np.array([0.229, 0.224, 0.225])
        self.data_dir = data_dir
        self.mode = mode
        self.color_t = color_type
        self.depth_t = depth_type
        self.transform = transforms.Compose([
                        transforms.ToTensor(),
                    ])
        if self.mode == 'train':
            f = open(self.data_dir+"/train.txt", "r")
        else:
            f = open(self.data_dir+"/test.txt", "r")
        for _, line in enumerate(f):
              self.name.append(line.replace("\n", ""))

    def __len__(self):
        return len(self.name)
    def __getitem__(self, idx):
        idx_name = self.name[idx]
        if self.color_t == 'jpg':
            color_img = cv2.imread(self.data_dir+"/color/color_"+idx_name+'.jpg')
        else:
            color_img = cv2.imread(self.data_dir+"/color/color_"+idx_name+'.png')
        color_img = color_img[:,:,[2,1,0]]
        color_img = cv2.resize(color_img,(224,224))
        color_origin = cv2.resize(color_img,(640,480))
        if self.depth_t == 'npy':
            depth_img = np.load(self.data_dir+"/depth_npy/depth_"+idx_name+'.npy')
            depth_origin = np.load(self.data_dir+"/depth_npy/depth_"+idx_name+'.npy').astype(float)
        elif self.depth_t == 'png':
            depth_img = cv2.imread(self.data_dir+"/depth/depth_"+idx_name+'.png', -1)
            depth_origin = cv2.imread(self.data_dir+"/depth/depth_"+idx_name+'.png', -1).astype(float)
        elif self.depth_t == 'jpg':
            depth_img = cv2.imread(self.data_dir+"/depth/depth_"+idx_name+'.jpg', -1)
            depth_origin = cv2.imread(self.data_dir+"/depth/depth_"+idx_name+'.jpg', -1).astype(float)
        if self.depth_t != 'npy':
            depth_img = depth_img[:,:,0]
            depth_origin = depth_origin[:,:,0]

        if depth_origin.shape[0] == 224:
            depth_origin = cv2.resize(depth_origin,(640,480))

        depth_img = cv2.resize(depth_img,(224,224))

        if self.mode == 'train':
            label_img = np.load(self.data_dir+"/label/label_"+idx_name+'.npy')

            f = open(self.data_dir+'/idx/id_'+idx_name+'.txt', "r")

            IDX = int(f.readlines()[0])

            # Unlabeled -> 2; unsuctionable -> 0; suctionable -> 1
            label_tmp = np.round(label_img[IDX]/255.*2.).astype(float)
            label = np.zeros((4,28,28))
            # Set label pixel
            label[IDX] = cv2.resize(label_tmp, (int(28), int(28)))
            label[IDX][label[IDX] != 0.0] = 1.0

            label_tensor = self.transform(label).float()

        # uint8 -> float
        color = (color_img/255.).astype(float)
        # BGR -> RGB and normalize
        color_rgb = np.zeros(color.shape)
        for i in range(3):
            color_rgb[:, :, i] = (color[:, :, 2-i]-self.image_net_mean[i])/self.image_net_std[i]

        depth_img = np.round((depth_img/np.max(depth_img))*255).astype('int').reshape(1,depth_img.shape[0],depth_img.shape[1])
        depth = (depth_img/1000.).astype(float) # to meters
        # D435 depth range
        depth = np.clip(depth, 0.0, 1.2)
        # Duplicate channel and normalize
        depth_3c = np.zeros(color.shape)
        for i in range(3):
            depth_3c[:, :, i] = (depth[:, :]-self.image_net_mean[i])/self.image_net_std[i]


        color_tensor = self.transform(color_rgb).float()
        depth_tensor = self.transform(depth_3c).float()


        if self.mode == 'train':
            sample = {"color": color_tensor, "depth": depth_tensor, "label": label_tensor, "id": IDX, "color_origin": color_origin, "depth_origin": depth_origin}
        else:
            sample = {"color": color_tensor, "depth": depth_tensor, "color_origin": color_origin, "depth_origin": depth_origin}

        return sample

class rosenberger_dataloader():
    def __init__(self, data_dir, color_type='jpg', depth_type='npy'):
        self.color_t = color_type
        self.depth_t = depth_type
        self.data_path = data_dir
        yolo = open(self.data_path+'/yolo_result.txt', "r")
        self.boxes = []
        for i, line in enumerate(yolo):
            data = line.replace("\n", "")
            if i%6 != 0:
                data = float(data)
                if data > 1.0:
                    data = data
                box.append(data)
            elif i == 0:
                box = []
            else:
                self.boxes.append(box)
                box = []
        self.name_list = []
        f = open(self.data_path+'/test.txt', "r")
        for i, line in enumerate(f):
            name = line.replace("\n", "")
            self.name_list.append(name)
        self.pt = 0

    def length(self):
        print(len(self.name_list))

    def get_next_data(self, vis_bbox=False):
        if self.pt >= len(self.name_list):
            self.pt = 0
        idx = self.name_list[self.pt]
        color = cv2.imread(self.data_path+'/color/color_'+idx+'.'+self.color_t)

        if self.depth_t == 'npy':
            depth = np.load(self.data_path+'/depth_npy/depth_'+idx+'.npy')
            depth = depth/1000.0
        else:
            depth = cv2.imread(self.data_path+'/depth/depth_'+idx+'.png',-1)
            depth = depth[:,:,0]/1000.0

        mask_hand = cv2.imread(self.data_path+'/mask_hand/mask_hand_'+idx+'.png', cv2.IMREAD_GRAYSCALE)
        mask_body = cv2.imread(self.data_path+'/mask_body/mask_body_'+idx+'.png', cv2.IMREAD_GRAYSCALE)
        mask_hand[mask_hand==30] = 0.0
        mask_body[mask_body==30] = 0.0

        depth_nan = np.isnan(depth).astype(np.uint8)

        best_box = self.boxes[self.pt]

        if vis_bbox:
            color_bbox = cv2.imread(self.data_path+'/color/color_'+idx+'.'+self.color_t)
            color_bbox = cv2.cvtColor(color_bbox, cv2.COLOR_BGR2RGB)
            box = self.boxes[self.pt]

            p_lu = (int(box[0]), int(box[1]))
            p_rd = (int(box[2]), int(box[3]))
            p_ld = (int(box[0]), int(box[3]))
            p_ru = (int(box[2]), int(box[1]))

            color_bbox = cv2.line(color_bbox,p_lu,p_ru,(0,255,0),3)
            color_bbox = cv2.line(color_bbox,p_ru,p_rd,(0,255,0),3)
            color_bbox = cv2.line(color_bbox,p_rd,p_ld,(0,255,0),3)
            color_bbox = cv2.line(color_bbox,p_ld,p_lu,(0,255,0),3)

            sample = {"color":color, "depth":depth, "depth_nan":depth_nan, "mask_hand":mask_hand, "mask_body":mask_body, "bbox":best_box, "color_bbox":color_bbox}
        else:
            sample = {"color":color, "depth":depth, "depth_nan":depth_nan, "mask_hand":mask_hand, "mask_body":mask_body, "bbox":best_box}

        self.pt += 1

        return sample

