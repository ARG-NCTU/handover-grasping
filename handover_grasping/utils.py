# AUTOGENERATED! DO NOT EDIT! File to edit: 02_utils.ipynb (unless otherwise specified).

__all__ = ['Image_table', 'get_grasp_line', 'get_affordancemap', 'get_model', 'get_pcd_right', 'get_pcd_left',
           'get_view', 'vis']

# Cell
import math
import cv2
import numpy as np
import os
import gdown
import open3d as o3d
from matplotlib import pyplot as plt


def Image_table(col, row, img_list, title_list=None):
    if len(img_list) == (col*row):
        fig = plt.figure(figsize=(10, 10))
        pt = 0
        for i in range(1, (col*row + 1)):
            fig.add_subplot(row, col, i)
            if title_list!= None:
                plt.title(title_list[pt])
            plt.axis('off')
            plt.imshow(img_list[pt])
            pt += 1

        plt.show()
    else:
        print("Image list length is not match !")


def get_grasp_line(theta, center, depth):
    """Generate grasping two endpoints of grasping line(8cm).

    Inputs:
      theta: degree
      center: x, y coordinate
      depth: depth image (mm)
    """
    depth = depth/1000.0
    if depth[center[0], center[1]] < 0.1:
        dis_ = (np.max(depth) + np.min(depth))*0.5
        dis = dis_ - 0.199
    else:
        dis = depth[center[0], center[1]] - 0.199

    length = int((148 - int(dis*50.955))/2)

    rad = math.radians(theta)
    if theta < 90:
        x1 = int(center[1] + length*abs(math.cos(rad)))
        y1 = int(center[0] - length*abs(math.sin(rad)))
        x2 = int(center[1] - length*abs(math.cos(rad)))
        y2 = int(center[0] + length*abs(math.sin(rad)))
    else:
        x1 = int(length*abs(math.cos(rad)) + center[1])
        y1 = int(length*abs(math.sin(rad)) + center[0])
        x2 = int(center[1] - length*abs(math.cos(rad)))
        y2 = int(center[0] - length*abs(math.sin(rad)))

    p1 = (x1, y1)
    p2 = (x2, y2)

    return p1, p2

def get_affordancemap(predict, depth, ConvNet=False):
    """Generate grasping point and affordancemap.

    Inputs:
      predict: output of HANet or ConvNet
      depth: depth image (mm)
    """
    if ConvNet:
        height = depth.shape[0]
        width = depth.shape[1]
        graspable = predict[0, 2].detach().cpu().numpy()
        thes = 0

    else:
        Max = []
        Re = []
        Angle = [90,135,0,45]
        height = depth.shape[0]
        width = depth.shape[1]
        re = np.zeros((4, height, width))

        for i in range(4):
            x, y = np.where(predict[0][i] == np.max(predict[0][i]))
            re[i] = cv2.resize(predict[0][i], (width, height))
            Max.append(np.max(predict[0][i]))
            Re.append(re[i])

        theta = Angle[Max.index(max(Max))]
        graspable = re[Max.index(max(Max))]
        thes = 1

    graspable = cv2.resize(graspable, (width, height))
    depth = cv2.resize(depth, (width, height))
    graspable [depth==0] = 0
    graspable[graspable>=thes] = 0.99999
    graspable[graspable<0] = 0
    graspable = cv2.GaussianBlur(graspable, (7, 7), 0)
    affordanceMap = (graspable/np.max(graspable)*255).astype(np.uint8)
    affordanceMap = cv2.applyColorMap(affordanceMap, cv2.COLORMAP_JET)
    affordanceMap = affordanceMap[:,:,[2,1,0]]

    gray = cv2.cvtColor(affordanceMap, cv2.COLOR_RGB2GRAY)
    blurred = cv2.GaussianBlur(gray, (11, 11), 0)
    binaryIMG = cv2.Canny(blurred, 20, 160)
    contours, _ = cv2.findContours(binaryIMG, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    i = 0
    point_x = 0
    point_y = 0
    cX = 0
    cY = 0
    x = 0
    y = 0

    for c in contours:
        M = cv2.moments(c)
        if(M["m00"]!=0):
            cX = int(M["m10"] / M["m00"])
            cY = int(M["m01"] / M["m00"])
            zc = depth[cY, cX]/1000
            i += 1
            point_x += cX
            point_y += cY

    if i != 0:
        x = int(point_x / i)
        y = int(point_y / i)
    else:
        x, y = np.where(predict[0][Max.index(max(Max))] == np.max(predict[0][Max.index(max(Max))]))
        x = int(x)
        y = int(y)

    if ConvNet:
        return affordanceMap, x, y
    else:
        return affordanceMap, x, y, theta

def get_model(depth=False):
    if depth:
        url = 'https://drive.google.com/u/1/uc?id=12dmpqU8_PqBPLdyW4in65X6meWWEdAwJ'
        name = 'HANet_depth'
    else:
        url = 'https://drive.google.com/u/1/uc?id=1jnlGIrqIXAIzOUjv2poJZMxxfzmtg1ET'
        name = 'HANet'
    path = os.path.abspath(os.getcwd())
    if not os.path.isfile(path+'/'+name + '.pth'):
        gdown.download(url, output=name + '.pth', quiet=False)

    return path + '/' + name + '.pth'

def get_pcd_right(rgb_np, depth_np, rotate_matrix):
    """Get pcd from RGB-D image and transfer it from camera_right to target frame

    Inputs:
      rgb_np: RGB image in numpy array type
      depth_np: DEPTH image in numpy array type
      rotate_matrix: transfer matrix for camera_right optical frame to target frame
    """
    axis = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.3, origin=[0,0,0])
    rgb = o3d.geometry.Image(rgb_np)
    depth = o3d.geometry.Image(depth_np)

    rgbd = o3d.geometry.RGBDImage.create_from_color_and_depth(rgb, depth, convert_rgb_to_intensity=False)
    pcd1 = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd, o3d.camera.PinholeCameraIntrinsic(o3d.camera.PinholeCameraIntrinsicParameters.PrimeSenseDefault))
    points1 = np.asarray(pcd1.points)
    pcd_sel1 = pcd1.select_by_index(np.where((points1[:, 2] > 0.25)&(points1[:, 2] < 1.3)&(points1[:, 1] < 0.15))[0])

    pcd_sel1.transform(rotate_matrix)
    axis.transform(rotate_matrix)

    return pcd_sel1, axis

def get_pcd_left(rgb_np, depth_np, rotate_matrix):
    """Get pcd from RGB-D image and transfer it from camera_left to target frame

    Inputs:
      rgb_np: RGB image in numpy array type
      depth_np: DEPTH image in numpy array type
      rotate_matrix: transfer matrix for camera_left optical frame to target frame
    """
    axis = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.3, origin=[0,0,0])
    rgb = o3d.geometry.Image(rgb_np)
    depth = o3d.geometry.Image(depth_np)

    rgbd = o3d.geometry.RGBDImage.create_from_color_and_depth(rgb, depth, convert_rgb_to_intensity=False)
    pcd2 = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd, o3d.camera.PinholeCameraIntrinsic(o3d.camera.PinholeCameraIntrinsicParameters.PrimeSenseDefault))
    points2 = np.asarray(pcd2.points)
    pcd_sel2 = pcd2.select_by_index(np.where((points2[:, 2] < 0.7)&(points2[:, 0] > -0.1))[0])
    pcd_sel2.transform(rotate_matrix)

    axis.transform(rotate_matrix)

    return pcd_sel2, axis

def get_view(pcd1, pcd2, front, lookat, up, zoom):
    """Generate multi-view RGB-D image from pointcloud

    Inputs:
      pcd1: pointcloud1
      pcd2: pointcloud2
      front, lookat, up, zoom: parameters to define view direction
    """
    vis = o3d.visualization.Visualizer()
    vis.create_window(visible=False)
    vis.get_render_option().point_color_option = o3d.visualization.PointColorOption.Color
    vis.add_geometry(pcd1)
    vis.update_geometry(pcd1)
    vis.add_geometry(pcd2)
    vis.update_geometry(pcd2)
    ctr = vis.get_view_control()
    ctr.set_lookat(lookat)
    ctr.set_front(front)
    ctr.set_up(up)
    ctr.set_zoom(zoom)
    opt = vis.get_render_option()
    opt.background_color = np.asarray([0, 0, 0])
    vis.update_renderer()
    vis.poll_events()
    image = vis.capture_screen_float_buffer(True)
    depth = vis.capture_depth_float_buffer(True)

    img = np.array(image)[414:695,740:1181,:]
    depth = np.array(depth)[414:695,740:1181]
    img = cv2.resize(img, (640,480))
    depth = cv2.resize(depth, (640,480))

    return img, depth

def vis(pcd_list, show_axis=False):
    """visualize pointcloud

    Inputs:
      pcd_list: list contain pcds [pcd1, pcd2,...,pcdn]
    """
    axis = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.3, origin=[0,0,0])
    vis = o3d.visualization.Visualizer()
    vis.create_window(visible=True)
    vis.get_render_option().point_color_option = o3d.visualization.PointColorOption.Color
    for pcd in pcd_list:
        vis.add_geometry(pcd)
        vis.update_geometry(pcd)
    if show_axis:
        vis.add_geometry(axis)
        vis.update_geometry(axis)
    ctr = vis.get_view_control()
    opt = vis.get_render_option()
    opt.background_color = np.asarray([0, 0, 0])
    vis.update_renderer()
    vis.poll_events()
    vis.run()
    vis.destroy_window()