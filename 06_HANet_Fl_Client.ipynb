{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "675614df",
   "metadata": {},
   "source": [
    "# Federated Learning example\n",
    "\n",
    "### This notebook is referenced by [Flower offical tutorial](https://flower.dev/docs/quickstart-pytorch.html).\n",
    "\n",
    "In this notebook we will learn how to train a HANet using Flower and PyTorch.\n",
    "We will using 3 client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e0ae41",
   "metadata": {},
   "source": [
    "# Server\n",
    "\n",
    "### If current PC is to be server, run above cell to start server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d8ab02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Tuple\n",
    "from typing import Optional\n",
    "import numpy as np\n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "\n",
    "import flwr as fl\n",
    "from flwr.common import Metrics\n",
    "\n",
    "from handover_grasping.model import HANet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0699f2ac",
   "metadata": {},
   "source": [
    "### Define strategy\n",
    "\n",
    "The strategy is to deal with model weight parameters delievered by clients, and the following example uses the averaging method and includes saving method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c9ffa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = HANet()\n",
    "class SaveModelAndMetricsStrategy(fl.server.strategy.FedAvg):\n",
    "    #\n",
    "    def aggregate_fit(\n",
    "        self,\n",
    "        rnd: int,\n",
    "        results: List[Tuple[fl.server.client_proxy.ClientProxy, fl.common.FitRes]], # FitRes is like EvaluateRes and has a metrics key \n",
    "        failures: List[BaseException],\n",
    "    ) -> Optional[fl.common.Weights]:\n",
    "\n",
    "        \"\"\"Aggregate model weights using weighted average and store checkpoint\"\"\"\n",
    "        aggregated_parameters_tuple = super().aggregate_fit(rnd, results, failures)\n",
    "        aggregated_parameters, _ = aggregated_parameters_tuple\n",
    "        # log_dict['aggregated_parameters']=aggregated_parameters\n",
    "        \n",
    "        if aggregated_parameters is not None:\n",
    "            print(f\"Saving round {rnd} aggregated_parameters...\")\n",
    "            # Convert `Parameters` to `List[np.ndarray]`\n",
    "            aggregated_weights: List[np.ndarray] = fl.common.parameters_to_weights(aggregated_parameters)\n",
    "            \n",
    "            # Convert `List[np.ndarray]` to PyTorch`state_dict`\n",
    "            params_dict = zip(net.state_dict().keys(), aggregated_weights)\n",
    "            state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "            net.load_state_dict(state_dict, strict=True)\n",
    "            torch.save(net.state_dict(), f\"model_round_{rnd}.pth\")\n",
    "            \n",
    "        return aggregated_parameters_tuple \n",
    "\n",
    "# Create strategy and run server\n",
    "strategy = SaveModelAndMetricsStrategy(min_fit_clients=3, min_available_clients=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3f94f3",
   "metadata": {},
   "source": [
    "### Server's IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dae5ba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVER_IP = 'your_own_IP'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97b6ba0",
   "metadata": {},
   "source": [
    "### Start Flower server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba4030f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flower 2022-07-20 15:07:21,001 | app.py:109 | Flower server running (10 rounds)\n",
      "SSL is disabled\n",
      "INFO - 2022-07-20 15:07:21,001 - app - Flower server running (10 rounds)\n",
      "SSL is disabled\n",
      "INFO flower 2022-07-20 15:07:21,005 | server.py:128 | Initializing global parameters\n",
      "INFO - 2022-07-20 15:07:21,005 - server - Initializing global parameters\n",
      "INFO flower 2022-07-20 15:07:21,006 | server.py:327 | Requesting initial parameters from one random client\n",
      "INFO - 2022-07-20 15:07:21,006 - server - Requesting initial parameters from one random client\n",
      "INFO flower 2022-07-20 15:08:11,729 | server.py:330 | Received initial parameters from one random client\n",
      "INFO - 2022-07-20 15:08:11,729 - server - Received initial parameters from one random client\n",
      "INFO flower 2022-07-20 15:08:11,730 | server.py:130 | Evaluating initial parameters\n",
      "INFO - 2022-07-20 15:08:11,730 - server - Evaluating initial parameters\n",
      "INFO flower 2022-07-20 15:08:11,732 | server.py:143 | FL starting\n",
      "INFO - 2022-07-20 15:08:11,732 - server - FL starting\n",
      "DEBUG flower 2022-07-20 15:08:20,126 | server.py:269 | fit_round: strategy sampled 3 clients (out of 3)\n",
      "DEBUG - 2022-07-20 15:08:20,126 - server - fit_round: strategy sampled 3 clients (out of 3)\n"
     ]
    }
   ],
   "source": [
    "ROUNDS = 10\n",
    "\n",
    "fl.server.start_server(\n",
    "    server_address=SERVER_IP+\":8080\",\n",
    "    config={\"num_rounds\": ROUNDS},\n",
    "    strategy=strategy,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ed4b26",
   "metadata": {},
   "source": [
    "# Client\n",
    "\n",
    "### If current PC is to be client, run above cell to start client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5387fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from handover_grasping import HANet\n",
    "import warnings\n",
    "from collections import OrderedDict\n",
    "\n",
    "import flwr as fl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456e14ed",
   "metadata": {},
   "source": [
    "### Target Server's IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19a1a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_SERVER_IP = 'your_own_IP'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d9f102",
   "metadata": {},
   "source": [
    "### Training, Testing and dataloader function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb6ddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, trainloader, epochs):\n",
    "    \"\"\"Train the model on the training set.\"\"\"\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr = 1e-3)\n",
    "    for _ in range(epochs):\n",
    "        for i_batch, sampled_batched in enumerate(trainloader):\n",
    "            optimizer.zero_grad()\n",
    "            color = sampled_batched['color'].cuda()\n",
    "            depth = sampled_batched['depth'].cuda()\n",
    "            label = sampled_batched['label'].permute(0,2,3,1).cuda().float()\n",
    "            criterion(net(color, depth), label).backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "def test(net, testloader):\n",
    "    \"\"\"Validate the model on the test set.\"\"\"\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    with torch.no_grad():\n",
    "        for i_batch, sampled_batched in enumerate(testloader):\n",
    "            color = sampled_batched['color'].cuda()\n",
    "            depth = sampled_batched['depth'].cuda()\n",
    "            labels = sampled_batched['label'].permute(0,2,3,1).cuda().float()\n",
    "            \n",
    "            outputs = net(color, depth)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            \n",
    "    return loss / len(testloader.dataset)\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    DATA_PATH = '/home/arg/handover_grasping/data/HANet_training_datasets'\n",
    "\n",
    "    dataset_train = handover_grasping_dataset(DATA_PATH, color_type='png', mode='train_split_1')\n",
    "    dataset_test = handover_grasping_dataset(DATA_PATH, color_type='png', mode='fl_test')\n",
    "\n",
    "    return DataLoader(dataset_train, batch_size = 8, shuffle = True, num_workers = 8), DataLoader(dataset_test, batch_size = 1, shuffle = False, num_workers = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc64ad9",
   "metadata": {},
   "source": [
    "### Initial HANet and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eca3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = HANet(4)\n",
    "net = net.cuda()\n",
    "\n",
    "trainloader, testloader = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f61764",
   "metadata": {},
   "source": [
    "### Define Flower client\n",
    "\n",
    "#### get_parameters\n",
    "\n",
    "1. return the model weight as a list of NumPy ndarrays\n",
    "\n",
    "#### set_parameters\n",
    "\n",
    "1. update the local model weights with the parameters received from the server\n",
    "\n",
    "#### fit\n",
    "\n",
    "1. set the local model weights\n",
    "2. train the local model\n",
    "3. receive the updated local model weights\n",
    "\n",
    "#### evaluate\n",
    "1. test the local model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e2332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def get_parameters(self):\n",
    "        return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "    def set_parameters(self, parameters):\n",
    "        params_dict = zip(net.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "        net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        train(net, trainloader, epochs=10)\n",
    "        return self.get_parameters(), len(trainloader.dataset), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        loss = test(net, testloader)\n",
    "        return loss, len(testloader.dataset), {\"accuracy\": 0.0}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbef0d80",
   "metadata": {},
   "source": [
    "### Start Flower client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01a9e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "fl.client.start_numpy_client(TARGET_SERVER_IP+\":8080\", client=FlowerClient())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
