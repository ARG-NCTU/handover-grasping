{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7141e251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eeaa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd48ce62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "image_net_mean = np.array([0.485, 0.456, 0.406])\n",
    "image_net_std  = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "class handover_grasping_dataset(Dataset):\n",
    "    \"\"\"Dataloader of handover datasets.\n",
    "    \"\"\"\n",
    "    name = []\n",
    "    def __init__(self, data_dir, mode='train'):\n",
    "        self.data_dir = data_dir\n",
    "        self.mode = mode\n",
    "        self.transform = transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                    ])\n",
    "        if self.mode == 'train':\n",
    "            f = open(self.data_dir+\"/train.txt\", \"r\")\n",
    "        else:\n",
    "            f = open(self.data_dir+\"/test.txt\", \"r\")\n",
    "        for _, line in enumerate(f):\n",
    "              self.name.append(line.replace(\"\\n\", \"\"))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.name)\n",
    "    def __getitem__(self, idx):\n",
    "        idx_name = self.name[idx]\n",
    "        color_img = cv2.imread(self.data_dir+\"/color/color_\"+idx_name+'.png')\n",
    "        color_img = color_img[:,:,[2,1,0]]\n",
    "        color_img = cv2.resize(color_img,(224,224))\n",
    "        color_origin = cv2.resize(color_img,(640,480))\n",
    "        depth_img = np.load(self.data_dir+\"/depth/depth_\"+idx_name+'.npy')\n",
    "        depth_origin = np.load(self.data_dir+\"/depth/depth_\"+idx_name+'.npy').astype(float)\n",
    "        if depth_origin.shape[0] == 224:\n",
    "            depth_origin = cv2.resize(depth_origin,(640,480))\n",
    "        depth_img = cv2.resize(depth_img,(224,224))\n",
    "\n",
    "        if self.mode == 'train':\n",
    "            label_img = np.load(self.data_dir+\"/label/label_\"+idx_name+'.npy')\n",
    "\n",
    "            f = open(self.data_dir+'/idx/id_'+idx_name+'.txt', \"r\")\n",
    "\n",
    "            IDX = int(f.readlines()[0])\n",
    "            \n",
    "            # Unlabeled -> 2; unsuctionable -> 0; suctionable -> 1\n",
    "            label_tmp = np.round(label_img[IDX]/255.*2.).astype(float)\n",
    "            label = np.zeros((4,28,28))\n",
    "            # Set label pixel\n",
    "            label[IDX] = cv2.resize(label_tmp, (int(28), int(28)))\n",
    "            label[IDX][label[IDX] != 0.0] = 1.0\n",
    "            \n",
    "            label_tensor = self.transform(label).float()\n",
    "\n",
    "        # uint8 -> float\n",
    "        color = (color_img/255.).astype(float)\n",
    "        # BGR -> RGB and normalize\n",
    "        color_rgb = np.zeros(color.shape)\n",
    "        for i in range(3):\n",
    "            color_rgb[:, :, i] = (color[:, :, 2-i]-image_net_mean[i])/image_net_std[i]\n",
    "\n",
    "        depth_img = np.round((depth_img/np.max(depth_img))*255).astype('int').reshape(1,depth_img.shape[0],depth_img.shape[1])\n",
    "        depth = (depth_img/1000.).astype(float) # to meters\n",
    "        # D435 depth range\n",
    "        depth = np.clip(depth, 0.0, 1.2)\n",
    "        # Duplicate channel and normalize\n",
    "        depth_3c = np.zeros(color.shape)\n",
    "        for i in range(3):\n",
    "            depth_3c[:, :, i] = (depth[:, :]-image_net_mean[i])/image_net_std[i]\n",
    "        \n",
    "        \n",
    "        color_tensor = self.transform(color_rgb).float()\n",
    "        depth_tensor = self.transform(depth_3c).float()\n",
    "        \n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            sample = {\"color\": color_tensor, \"depth\": depth_tensor, \"label\": label_tensor, \"id\": 0, \"color_origin\": color_origin, \"depth_origin\": depth_origin}\n",
    "        else:\n",
    "            sample = {\"color\": color_tensor, \"depth\": depth_tensor, \"color_origin\": color_origin, \"depth_origin\": depth_origin}\n",
    "        \n",
    "        return sample"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
